################################################################################
# SPDX-FileCopyrightText: Copyright (c) 2020-2021 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

# Following properties are mandatory when engine files are not specified:
#   int8-calib-file(Only in INT8)
#   Caffemodel mandatory properties: model-file, proto-file, output-blob-names
#   UFF: uff-file, input-dims, uff-input-blob-name, output-blob-names
#   ONNX: onnx-file
#
# Mandatory properties for detectors:
#   num-detected-classes
#
# Optional properties for detectors:
#   cluster-mode(Default=Group Rectangles), interval(Primary mode only, Default=0)
#   custom-lib-path,
#   parse-bbox-func-name
#
# Mandatory properties for classifiers:
#   classifier-threshold, is-classifier
#
# Optional properties for classifiers:
#   classifier-async-mode(Secondary mode only, Default=false)
#
# Optional properties in secondary mode:
#   operate-on-gie-id(Default=0), operate-on-class-ids(Defaults to all classes),
#   input-object-min-width, input-object-min-height, input-object-max-width,
#   input-object-max-height
#
# Following properties are always recommended:
#   batch-size(Default=1)
#
# Other optional properties:
#   net-scale-factor(Default=1), network-mode(Default=0 i.e FP32),
#   model-color-format(Default=0 i.e. RGB) model-engine-file, labelfile-path,
#   mean-file, gie-unique-id(Default=0), offsets, process-mode (Default=1 i.e. primary),
#   custom-lib-path, network-mode(Default=0 i.e FP32)
#
# The values in the config file are overridden by values set through GObject
# properties.

[property]
gpu-id=0  
#Integer 0: RGB 1: BGR 2: GRAY
#model-color-format=0
#Infer Processing Mode 1=Primary Mode 2=Secondary Mode
#process-mode=1  
net-scale-factor=0.0039215697906911373

model-engine-file=/opt/nvidia/deepstream/deepstream/samples/models/tao_pretrained_models/YOLOv8-TensorRT/yolov8s-pose-dy-sim-640.engine

## set a unique identifier for each instance of the GIE (GPU Inference Engine)
gie-unique-id=1

## [Gst-nvdspreprocess & Gst-nvdspostprocess plugin]
## 0=Detector, 1=Classifier, 2=Segmentation, 100=Other
network-type=100
#Integer 0: FP32 1: INT8 2: FP16
network-mode=2

 
#When a network supports both implicit batch dimension and full dimension, force the implicit batch dimension mode. Boolean
#force-implicit-batch-dim=1
#batch-size=1

#infer-dims=3;640;640
#output-blob-names=output0 

#num-detected-classes=1   
maintain-aspect-ratio=1
symmetric-padding=1
## Bilinear Interpolation
#scaling-filter=1
scaling-compute-hw=1
#disable-output-host-copy=1
## Specifies the number of consecutive batches to be skipped for inference
#interval=1

#is-classifier=0
## Integer 0: OpenCV groupRectangles() 1=DBSCAN, 2=NMS, 3= DBSCAN+NMS Hybrid, 4 = None(No clustering)
#cluster-mode=2
#parse-bbox-func-name=nvdsparsebbox_YoloPose



## if batch-size!=1 ã€‚  12 (batch) x 6 (default for 1 source) =72
#tensor-meta-pool-size=72 

## nvinfer plugin then attaches the tensor meta to the input buffer.
output-tensor-meta=1

## start from DS6.2
#crop-objects-to-roi-boundary=1


## [class-attrs-all]
#threshold=0.7
#nms-iou-threshold=0.20
#pre-cluster-threshold=0.25
#topk=300
